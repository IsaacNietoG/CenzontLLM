# CenzontLLM 

**Framework open-source para generar podcasts cient√≠ficos en espa√±ol a partir de papers (PDF ‚Üí voces realistas)**

> *"Cenzontli" = 400 en n√°huatl ‚Üí 400 voces para la ciencia.

![CenzontLLM](https://img.shields.io/badge/CenzontLLM-Podcast_Science-blue?style=for-the-badge&logo=soundcloud)
![Python](https://img.shields.io/badge/python-3.10%20%7C%203.11%20%7C%203.12-blue)
![License](https://img.shields.io/github/license/IsaacNietoG/cenzontllm)
![Status](https://img.shields.io/badge/status-MVP_in_progress-yellow)

---

## ¬øQu√© hace?

Convierte **cualquier art√≠culo cient√≠fico (PDF)** en un **podcast conversacional profesional** con:

- 1‚Äì3 hosts/guests con personalidades √∫nicas
- Di√°logos naturales, fieles al paper
- Voces realistas en espa√±ol (neutro + acentos regionales)
- M√∫sica, efectos y normalizaci√≥n profesional
- **100% autom√°tico, cloud low-cost (esperado: <$1/episodio)**

---

## üöÄ Inicio R√°pido (local, pero sugiero usar Docker)

### Requisitos Previos

- **Python**: 3.10, 3.11 o 3.12
- **Poetry**: Para gesti√≥n de dependencias ([instalaci√≥n](https://python-poetry.org/docs/#installation))
- **Sistema operativo**: Linux, macOS o WSL2 (Windows)
- **Opcional**: Docker + NVIDIA GPU (para procesamiento de im√°genes)

### Instalaci√≥n

1. **Clonar el repositorio:**
   ```bash
   git clone https://github.com/IsaacNietoG/cenzontllm.git
   cd cenzontllm
   ```

2. **Instalar dependencias con Poetry:**
   ```bash
   poetry install
   ```

3. **Activar el entorno virtual:**
   ```bash
   poetry shell
   ```

4. **Configurar variables de entorno:**
   
   Crea un archivo `.env` en la ra√≠z del proyecto:
   ```bash
   cp .env.example .env  # Si existe, o crea uno nuevo
   ```
   
   Edita `.env` y agrega tu API key de Groq (opcional para modo mock):
   ```env
   CENZONT_GROQ_API_KEY=tu_api_key_aqui
   CENZONT_RUN_MODE=mock  # o "groq" para usar LLM real
   CENZONT_MODEL=llama-3.3-70b-versatile
   CENZONT_NUM_GUESTS=1
   CENZONT_TARGET_MINUTES=20
   ```

### Uso B√°sico

#### 1. Procesar un PDF cient√≠fico

Extrae el contenido del PDF y genera un archivo JSON estructurado:

```bash
python -m src.cenzontllm.main input ruta/al/paper.pdf
```

Esto genera `paper_content.json` con:
- Metadatos (t√≠tulo, autores, DOI, a√±o)
- Secciones detectadas (Abstract, Introduction, Methods, Results, etc.)
- Figuras extra√≠das (con captions placeholder)

#### 2. Generar el guion del podcast

Desde el JSON generado, crea un guion conversacional:

**Modo Mock (r√°pido, sin API):**
```bash
python -m src.cenzontllm.main guion paper_content.json --mock
```

**Modo Groq (requiere API key):**
```bash
python -m src.cenzontllm.main guion paper_content.json --no-mock
```

El guion se guarda en `guion_podcast.md` con formato Markdown.

#### 3. Pipeline completo (en desarrollo)

```bash
python -m src.cenzontllm.main run paper.pdf --output podcast.mp3
```

> ‚ö†Ô∏è **Nota**: El comando `run` a√∫n no est√° implementado. Por ahora, usa los pasos 1 y 2 por separado.

---

## üìã Ejemplo Completo

Ejemplo funcional incluido en el repositorio:

```bash
# 1. Procesar el PDF de ejemplo
python -m src.cenzontllm.main input examples/attentionIsAllYouNeed/attentionIsAllYouNeed.pdf

# 2. Generar el guion
python -m src.cenzontllm.main guion examples/attentionIsAllYouNeed/paper_content.json --mock

# 3. Ver el resultado
cat guion_podcast.md
```

El ejemplo usa el paper "Attention Is All You Need" (Vaswani et al., 2017) y genera un guion de podcast con Ana (host) y un experto invitado.

---

## üèóÔ∏è Arquitectura

> üìñ **Documentaci√≥n completa**: Ver [ARCHITECTURE.md](ARCHITECTURE.md) para detalles t√©cnicos detallados.

```mermaid
graph LR
    A[PDF] --> B[Input Processor]
    B --> C[paper_content.json]
    C --> D[Guionizador Multi-Agent]
    D --> E[guion_podcast.md]
    E --> F[TTS - En desarrollo]
    F --> G[podcast.mp3]
    
    subgraph "Input Processor"
        B1[Extractor de Metadatos]
        B2[Particionado PDF]
        B3[Detecci√≥n de Secciones]
        B4[Extracci√≥n de Figuras]
    end
    
    subgraph "Guionizador"
        D1[HostAgent]
        D2[GuestAgent]
        D3[WriterAgent]
        D4[LangGraph Workflow]
    end
```

### Componentes Principales

1. **Input Processor** (`src/cenzontllm/input_processor/`)
   - Extrae metadatos del PDF (t√≠tulo, autores, DOI)
   - Particiona el documento usando `unstructured`
   - Detecta secciones autom√°ticamente (Abstract, Introduction, Methods, Results, Discussion, Conclusion)
   - Extrae figuras (captioning con GPU pendiente)

2. **Guionizador** (`src/cenzontllm/guionizador/`)
   - **HostAgent**: Genera personalidades de invitados y outline del podcast
   - **GuestAgent**: Responde preguntas como experto con personalidad √∫nica
   - **WriterAgent**: Convierte la conversaci√≥n en guion profesional con formato Markdown
   - **Workflow LangGraph**: Orquesta la conversaci√≥n iterativa entre agentes

3. **CLI** (`src/cenzontllm/main.py`)
   - Interfaz de l√≠nea de comandos con Typer
   - Comandos: `input`, `guion`, `run` (en desarrollo)

Para m√°s detalles sobre el dise√±o, flujo de datos, decisiones t√©cnicas y extensiones futuras, consulta [ARCHITECTURE.md](ARCHITECTURE.md).

---

## üìä Estado Actual del Proyecto

| Componente | Estado | Descripci√≥n |
|------------|--------|-------------|
| **Input Processor** | ‚úÖ **Funcional** | Extrae metadatos, particiona PDF, detecta secciones. Funciona con PDFs en espa√±ol e ingl√©s. |
| **Guionizador** | ‚úÖ **Funcional** | Sistema multi-agente completo. Genera guiones en modo mock y con Groq API. |
| **Modo Mock** | ‚úÖ **Completo** | Permite probar el sistema sin API keys. Respuestas predefinidas para desarrollo. |
| **Integraci√≥n Groq** | ‚úÖ **Completo** | Soporte para Llama 3.3 70B a trav√©s de Groq API. |
| **CLI** | ‚úÖ **Funcional** | Comandos `input` y `guion` operativos. |
| **Docker** | ‚úÖ **Listo** | Dockerfile con CUDA para procesamiento GPU. |
| **TTS (Text-to-Speech)** | üöß **Pendiente** | Conversi√≥n de guion a audio. |
| **Pipeline Completo** | üöß **Pendiente** | Comando `run` que integre todo el flujo. |
| **Captioning de Figuras** | üöß **Pendiente** | Descripci√≥n autom√°tica de figuras con modelos de visi√≥n. |
| **Integraci√≥n Ollama** | üöß **Pendiente** | Soporte para modelos locales. |

### Funcionalidades Implementadas

‚úÖ Extracci√≥n completa de contenido de PDFs cient√≠ficos  
‚úÖ Detecci√≥n autom√°tica de secciones (Abstract, Introduction, Methods, Results, Discussion, Conclusion)  
‚úÖ Generaci√≥n de personalidades de invitados con acentos regionales  
‚úÖ Creaci√≥n de outline estructurado para el podcast  
‚úÖ Conversaci√≥n multi-agente con evaluaci√≥n iterativa  
‚úÖ Generaci√≥n de guiones en formato Markdown con anotaciones de voz  
‚úÖ Modo mock para desarrollo sin costos de API  
‚úÖ Integraci√≥n con Groq API para LLMs de producci√≥n  

### Pr√≥ximos Pasos

- [ ] Implementar TTS (Text-to-Speech) con voces en espa√±ol
- [ ] Completar pipeline end-to-end (`run` command)
- [ ] Captioning de figuras con modelos de visi√≥n (LLaVA, GPT-4V)
- [ ] Integraci√≥n con Ollama para modelos locales
- [ ] Post-procesamiento de audio (m√∫sica, efectos, normalizaci√≥n)
- [ ] Tests unitarios y de integraci√≥n
- [ ] Documentaci√≥n de API

---

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno

Crea un archivo `.env` en la ra√≠z del proyecto:

```env
# Modo de ejecuci√≥n: "mock" (sin API) o "groq" (con Groq API)
CENZONT_RUN_MODE=mock

# API Key de Groq (requerido si RUN_MODE=groq)
# Obt√©n tu key en: https://console.groq.com/
CENZONT_GROQ_API_KEY=

# Modelo a usar (Groq u Ollama)
CENZONT_MODEL=llama-3.3-70b-versatile

# N√∫mero de invitados en el podcast (1-3)
CENZONT_NUM_GUESTS=1

# Rondas m√°ximas de conversaci√≥n
CENZONT_MAX_REPLICA_ROUNDS=2

# Duraci√≥n objetivo del podcast (minutos)
CENZONT_TARGET_MINUTES=20
```

### Configuraci√≥n Avanzada

Las configuraciones se pueden modificar en `src/cenzontllm/guionizador/config.py` o mediante variables de entorno con prefijo `CENZONT_`.

---

## üê≥ Uso con Docker

### Construir la imagen

```bash
docker build -t cenzontllm .
```

### Ejecutar

```bash
# Procesar PDF
docker run --rm -v "$(pwd)":/app cenzontllm input examples/attentionIsAllYouNeed.pdf
# Generar guion
docker run --rm -v "$(pwd)":/app --env-file .env cenzontllm guion examples/attentionIsAllYouNeed/paper_content.json
```


---

## üõ†Ô∏è Desarrollo

### Estructura del Proyecto

```
CenzontLLM/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ cenzontllm/
‚îÇ       ‚îú‚îÄ‚îÄ input_processor/    # Procesamiento de PDFs
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ extractor.py    # Particionado con unstructured
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ metadata.py     # Extracci√≥n de metadatos
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ section_detector.py  # Detecci√≥n de secciones
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ figure_captioner.py  # Captioning de figuras (WIP)
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py     # Pipeline principal
‚îÇ       ‚îú‚îÄ‚îÄ guionizador/        # Sistema multi-agente
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ agents/
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py     # Clase base para agentes
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ host.py     # HostAgent
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ guest.py    # GuestAgent
‚îÇ       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ writer.py   # WriterAgent
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ graph.py        # Workflow LangGraph
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ prompts.py      # Prompts para LLMs
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ config.py       # Configuraci√≥n
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ mocks.py        # Respuestas mock
‚îÇ       ‚îî‚îÄ‚îÄ main.py             # CLI principal
‚îú‚îÄ‚îÄ examples/                   # Ejemplos de uso
‚îú‚îÄ‚îÄ Dockerfile                  # Imagen Docker
‚îú‚îÄ‚îÄ pyproject.toml             # Dependencias Poetry
‚îî‚îÄ‚îÄ README.md                  # Este archivo
```

### Modo Mock vs. Modo Groq

**Modo Mock** (`--mock`):
- No requiere API keys
- Respuestas predefinidas para desarrollo
- √ötil para probar la estructura del workflow
- R√°pido y sin costos

**Modo Groq** (`--no-mock`):
- Usa Groq API con Llama 3.3 70B
- Genera contenido real basado en el paper
- Requiere `CENZONT_GROQ_API_KEY`
- Costos seg√∫n uso de la API

---

## üêõ Troubleshooting

### Error: "No module named 'unstructured'"

**Soluci√≥n**: Instala las dependencias con Poetry:
```bash
poetry install
```

### Error: "GROQ_API_KEY not found"

**Soluci√≥n**: 
- Si usas modo mock: no necesitas la key, usa `--mock`
- Si usas modo Groq: crea `.env` con `CENZONT_GROQ_API_KEY=tu_key`

### Error al procesar PDF: "Tesseract not found"

**Soluci√≥n**: Instala Tesseract OCR:
```bash
# Ubuntu/Debian
sudo apt-get install tesseract-ocr

# macOS
brew install tesseract

# Windows (WSL)
sudo apt-get install tesseract-ocr
```

### El guion generado est√° vac√≠o o incompleto

**Posibles causas**:
- El PDF no tiene texto extra√≠ble (es una imagen escaneada)
- El modo mock est√° limitado, prueba con `--no-mock`
- El paper es muy corto o no tiene secciones claras

**Soluci√≥n**: Verifica que `paper_content.json` tenga contenido v√°lido antes de generar el guion.

---

## üìö Dependencias Principales

- **LangGraph**: Orquestaci√≥n de workflows multi-agente
- **LangChain Core**: Integraci√≥n con LLMs
- **Unstructured**: Procesamiento avanzado de PDFs
- **PyMuPDF**: Lectura de PDFs
- **Groq**: API para LLMs r√°pidos
- **Typer**: CLI moderna
- **Pydantic**: Validaci√≥n de datos y configuraci√≥n

Ver `pyproject.toml` para la lista completa.

---

## üìÑ Licencia

[Apache 2.0](LICENSE)

---

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request


> Hecho con ‚ù§Ô∏è y LLMs open-source.  

